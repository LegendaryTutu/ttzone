{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理二分类的问题\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data['data']\n",
    "Y = data['target']\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, \n",
    "                                                test_size = 0.3\n",
    "                                                ,random_state = 5  # 5最优\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用xgboost原生的包\n",
    "# 将数据转化成xgboost自己能读懂的数据结构\n",
    "\n",
    "\n",
    "# 参数字典设置\n",
    "\n",
    "# 尝试自己调整这些参数，看下在测试集上的分数\n",
    "\n",
    "# 设置一下watchlist\n",
    "# 从而使得xgboost在拟合训练集的时候，不仅是不断提升训练集上的分数，而且也同时观测测试机上的分数\n",
    "\n",
    "\n",
    "# 开始训练模型， 训练模型的过程中，可以尝试设置很大的基分类器的个数\n",
    "# 并且通过设置'提前停止'的条件从而使得迭代提早停止\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个时候binary : logistic给出的predict结果是sigmod转化之后的类概率的值\n",
    "# 需要自己定义一个函数来将其转换成最后的结果\n",
    "# 使用自定义的函数将最后的结果进行0.5的处理，大于0.5的预测成1，小于则预测成0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何使用xgboost的交叉验证，当前是xgboost原生的包，无法使用cross_validate_score\n",
    "\n",
    "# 在做交叉验证的时候也可以尝试设置评估指标，通过评估指标，来在适当的时候停止迭代\n",
    "# 并且将交叉验证在训练集上的分数和测试集上的分数全都打印出来\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以尝试使用测试集迭代完之后的模型来进行参数的调优，我们可以使用以下的方式\n",
    "params = {\n",
    "    'objective' : 'binary:logistic',#目标函数，逻辑回归，predict输出为类概率\n",
    "    #'objective' : 'binary:logitraw',#目标函数，逻辑回归，给出的是做sigmod转换之前的值\n",
    "    'booster' : 'gbtree',#基分类器的种类\n",
    "    'eta' : 0.1,#学习率,默认值是0.1\n",
    "    'gamma' : 0,#后剪枝的过程,0到正无穷, 默认0，尝试0, 1，5，10，100\n",
    "    'min_child_weight':1,#叶子节点权重分数的下界\n",
    "    'max_depth': 5, #最大深度\n",
    "    'eval_metric' : ['auc','error']\n",
    "}\n",
    "\n",
    "d_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将图给画出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从上面的max_depth调优之中，我们看到max_depth在等于3的时候，交叉验证里测试集上的分数是最高的\n",
    "# 接着我们保证max_depth = 3 的前提下，对其他的参数调优\n",
    "# 这个过程较为繁琐，可以尝试使用sklearn的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试使用随机森林，查看这份数据集下，随机森林得出的结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost的原生的包不能放入gridsearchcv进行调参, 不好调参\n",
    "# 但是xgboost也提供了sklearn的API\n",
    "# 小试牛刀一下XGBClassifier\n",
    "# 尝试使用cross_validate_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化详细的了解一下fit方法\n",
    "# 在fit里面也是可以尝试使用的参数, 查看作重要的几个\n",
    "# eval_set, 在训练的过程当中，也可以查看在训练集上的分数和测试集上的分数\n",
    "# eval_metric, 到底使用什么指标来进行计算\n",
    "# early_stopping_rounds, 在eval_set最后一个元素上，检测每一次跌倒的分数\n",
    "# 如果在指定的次数内，eval_metric的分数没有一个较大的提升，就终止迭代\n",
    "# verbose, 指的是是否要打印出每一次迭代的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个时候由于是sklearn的API，则可以使用grid_search_cv来做网格搜索了\n",
    "# 每个参数的范围，可以尝试通过每个参数的学习曲线去找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将grid_search_cv的参数放入原生的xgb里面进行计算\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每一个数的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一个树的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将最后的结果保存下来，每一个数具体的信息就可以保存txt当总\n",
    "# 这种txt文件可以后期进行一些处理，将其转换成sql语句，作用于数据库中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何来保存模型，有两种方法\n",
    "\n",
    "# 第一种是直接使用.save_model的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二种比较常用，使用的是pickle的方式来保存\n",
    "# pickle几乎能保存所有可能的类\n",
    "\n",
    "#首先要打开一个文件，然后将模型写进去\n",
    "#如果是要写一个二进制文件的话，就需要用wb, write binary在写入\n",
    "\n",
    "#从二进制文件读取模型\n",
    "\n",
    "#调用出来之前上模型来预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多分类问题的,小麦种子的案例\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/00236/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出数据集里的X与Y\n",
    "\n",
    "# 查看Y的标签\n",
    "\n",
    "# 这个时候观测到数据集的标签是从1打头的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于多分类的问题来说\n",
    "# 需要更改objective为multi:softmax, 也需要指定num_class\n",
    "\n",
    "# 尝试设置简单的params来拟合数据\n",
    "\n",
    "# 尝试开始训练数据\n",
    "# 这个时候会报错，报错的信息提示label里面必须是从0开始的，但是当前的标签是从1开始的\n",
    "\n",
    "# 所以需要将label里面的值减一个\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按正常的方式来切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置多分类问题的参数，并且拟合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax是直接给出预测的标签值，不是类概率\n",
    "# 可以直接使用sklearn的accuracy_score方法来计算准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型表现不怎么样，xgboost不行的话，看一下rfc和ada的表现呢\n",
    "\n",
    "# 发现rfc和ada表现都不咋滴，还是xgboost略微高一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小试牛刀尝试使用sklearn的API\n",
    "\n",
    "# API可以直接使用交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始设置一些参数的范围，开始网格搜索\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置多分类的参数，使用xgboost原生的包\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回归类问题\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error as MSE, r2_score\n",
    "\n",
    "#导入数据并且切分数据集\n",
    "data = load_boston()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = 0.3\n",
    "                                                , random_state = 420\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实例化模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试使用cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 和随机森林回归来比较\n",
    "\n",
    "# 也看一下cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用类DMatrix读取数据, 特征矩阵和标签进行一起传入\n",
    "\n",
    "# 并且这里也介绍一些新的参数 \n",
    "# colsample_bytree 列的随机采样\n",
    "# subsample bootstrap样本的有放回随机采样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算出MSE和r2分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试使用网格搜索的方式来找最优参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将最优的参数放入在原生的包里面查看最后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 之前使用的是rmse来进行判定的，此时如果我们想自定义一个评估标准的话可以写一个函数出来\n",
    "\n",
    "# 定义一个计算R平方的函数，注意return记结果的格式有规则，不然xgb不认识\n",
    "\n",
    "\n",
    "# 定义好函数之后，在train里面放入到feval\n",
    "\n",
    "# 查看最后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 常规参数\n",
    "booster\n",
    "    gbtree 树模型做为基分类器（默认）\n",
    "    gbliner 线性模型做为基分类器\n",
    "silent\n",
    "    silent=0时，输出中间过程（默认）\n",
    "    silent=1时，不输出中间过程\n",
    "nthread\n",
    "    nthread=-1时，使用全部CPU进行并行运算（默认）\n",
    "    nthread=1时，使用1个CPU进行运算。\n",
    "scale_pos_weight\n",
    "    正样本的权重，在二分类任务中，当正负样本比例失衡时，设置正样本的权重，模型效果更好。例如，当正负样本比例为1:10时，scale_pos_weight=10。\n",
    "        \n",
    "#模型参数\n",
    "\n",
    "n_estimatores\n",
    "    含义：总共迭代的次数，即决策树的个数\n",
    "    调参：\n",
    "early_stopping_rounds\n",
    "    含义：在验证集上，当连续n次迭代，分数没有提高后，提前终止训练。\n",
    "    调参：防止overfitting。\n",
    "max_depth\n",
    "    含义：树的深度，默认值为6，典型值3-10。\n",
    "    调参：值越大，越容易过拟合；值越小，越容易欠拟合。\n",
    "min_child_weight\n",
    "    含义：默认值为1,。\n",
    "    调参：值越大，越容易欠拟合；值越小，越容易过拟合（值较大时，避免模型学习到局部的特殊样本）。\n",
    "subsample\n",
    "    含义：训练每棵树时，使用的数据占全部训练集的比例。默认值为1，典型值为0.5-1。\n",
    "    调参：防止overfitting。\n",
    "colsample_bytree\n",
    "    含义：训练每棵树时，使用的特征占全部特征的比例。默认值为1，典型值为0.5-1。\n",
    "    调参：防止overfitting。\n",
    "    \n",
    "\n",
    "# 学习任务参数\n",
    "\n",
    "learning_rate\n",
    "    含义：学习率，控制每次迭代更新权重时的步长，默认0.3。\n",
    "    调参：值越小，训练越慢。\n",
    "    典型值为0.01-0.2。\n",
    "objective 目标函数\n",
    "    回归任务\n",
    "        reg:linear (默认)\n",
    "        reg:logistic \n",
    "    二分类\n",
    "        binary:logistic     概率 \n",
    "        binary：logitraw   类别\n",
    "    多分类\n",
    "        multi：softmax  num_class=n   返回类别\n",
    "        multi：softprob   num_class=n  返回概率\n",
    "    rank:pairwise \n",
    "eval_metric\n",
    "    回归任务(默认rmse)\n",
    "        rmse--均方根误差\n",
    "        mae--平均绝对误差\n",
    "    分类任务(默认error)\n",
    "        auc--roc曲线下面积\n",
    "        error--错误率（二分类）\n",
    "        merror--错误率（多分类）\n",
    "        logloss--负对数似然函数（二分类）\n",
    "        mlogloss--负对数似然函数（多分类）\n",
    "\n",
    "gamma\n",
    "    惩罚项系数，指定节点分裂所需的最小损失函数下降值。\n",
    "    调参：\n",
    "alpha\n",
    "    L1正则化系数，默认为1\n",
    "lambda\n",
    "    L2正则化系数，默认为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
